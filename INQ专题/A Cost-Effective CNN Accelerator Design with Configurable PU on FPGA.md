# 题目：一种成本效益CNN加速器设计与可配置的PU在FPGA上
## 来源：IEEE计算机学会超大规模集成电路年会
## 摘要：
卷积神经网络(cnn)正在迅速发展，并得到了广泛的应用。尽管cnn广受欢迎，但由于庞大的数据量、密集的计算和频繁的内存访问，
在便携式系统上部署cnn仍然具有挑战性。因此，人们提出了许多降低CNN模型复杂度的方法，如模型剪枝和量化。然而，它也带来了
新的挑战。例如，现有的设计通常采用通道尺寸瓷砖，需要规则的通道数量。剪枝后的信道数可能会变得非常不规则，造成大量的零
填充和资源浪费。对于量化来说，简单的激进的比特减少通常会导致较大的精度下降。为了解决这些挑战，在本工作中，首先我们提
出在核维中使用基于行的平铺，以适应不同的核大小和通道数，并显著减少零填充。此外，我们开发了可动态分组或分割的可配置处
理单元(PUs)设计，以支持平铺的灵活性和实现高效的硬件资源共享。至于量化，我们考虑了最近提出的增量网络量化(INQ)算法，该
算法使用2次幂格式的低比特表示权值，因此能够以最小的计算复杂度表示权值，因为昂贵的乘法可以转换为廉价的移位操作。我们进
一步提出一种基于近似移位器的处理单元(PE)设计，作为处理单元的基本构造块，以方便卷积计算。最后，在Stratix v独立的FPGA
上实现了INQ量化AlexNet的rtls级实现，与目前的设计相比，我们的加速器实现了1.87倍的性能，证明了所提出的设计方法的有效性。
## 关键词：卷积神经网络、FPGA、硬件加速
