# 《基于ＦＰＧＡ的卷积神经网络专用异构加速器的研究》

## 来源：山东大学硕士论文

## 摘要：
近些年来，深度学习己经成为了一个热门的研究领域，其中卷积神经网络（ＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｕｒａｌＮｅｔｗｏｒｋｊＣＮＮ）已经在诸如文字辨认、图片分类、目标检测等很多深度学习的领域上取得了巨大的成功。然而在一个ＣＮＮ模型的前向推理计算过程中，往往需要百万次甚至上亿次浮点乘累加运算以及浮点参数的存储，使用传统的ＣＰＵ或者ＧＰＵ并不能充分挖掘ＣＮＮ内部并行计算的特性。ＦＰＧＡ具有低功耗、灵活可编程和开发周期短的特点，其内部的逻辑单元能够以较低的功耗完成并行计算的任务，因此ＦＰＧＡ是ＣＮＮ加速协处理器设计的理想选择。本课题基于Ｘｉｌｉｎｘ公司的Ｚｙｎｑ系列ＦＰＧＡ，利用其ＣＰＵ＋ＦＰＧＡ的异构ＳｏＣ开发平台，采用ＶｅｒｉｌｏｇＨＤＬ硬件描述语言研宄实现了ＣＮＮ专用异构加速协处理器。其中ＣＰＵ完成软件程序部分的发送图片、轮询、中断、显示分类结果等任务，ＦＰＧＡ完成ＣＮＮ模型的具体计算任务。本文首先对ＣＮＮ的历史发展以及ＣＮＮ加速协处理器的研宄现状进行了介绍，然后通过对ＣＮＮ前向推理的计算过程以及整体结构进行分析，详细探讨了计算过程中存在的并行性，并提出了不同并行性的实现方法及其相应的资源和带宽需求。针对广泛应用于手写体数字识别的卷积神经网络ＬｅＮｅｔ－５，本文首先利用英特尔动态网络裁剪技术将网络模型的大小进行了压缩，然后利用英特尔增量网络量化技术将模型中３２比特的浮点参数量化为８比特的定点参数，并进一步优化为５比特参数来设计专用的“定点移位乘法器”。本文使用Ｖｅｒｉｌｏｇ语言分别设计了乘累加阵列、池化采样、激活函数和四舍五入等计算模块，并基于流水线技术的设计思想将各计算模块进行整合，最终形成了计算精度为８比特的ＣＮＮ硬件计算电路，实现了ＬｅＮｅｔ－５网络的前向推理计算。以此为基础，本文提出了两种不同的异构ＳｏＣ系统，并分别介绍了两套系统的整体架构、缓存策略以及ＰＳ和ＰＬ的设计。然后基于对ＳｏＣ系统的建模，对两套系统分别进行了仿真验证。针对Ｍｎｉｓｔ测试集的１００００张测试图片，本设计达到了９８．９％的识别精度。实验结果表明，在优化的ＳｏＣ系统中，ＦＰＧＡ在ｌＯＯＭｈｚ的时钟频率下完成一幅手写体数字图片的推理计算耗时２４ｕｓ，其均值计算能力达到了１５．２１ＧＭＡＣ／Ｓ，峰值计算能力达到了３３．６ＧＭＡＣ／Ｓ，性能功耗比为６．８８９０ＧＭＡＣ／Ｗ，性能功耗比为通用ＣＰＵ的１５２０倍，通用ＧＰＵ的１６０倍，其中ＣＰＵ为英特尔ｉ５－８４００处理器，ＧＰＵ为ＧＴＸ－１０５０Ｔｉ显卡。

## 关键词：
ＣＮＮ加速协处理器；ＦＰＧＡ；ＳｏＣ系统；移位计算
